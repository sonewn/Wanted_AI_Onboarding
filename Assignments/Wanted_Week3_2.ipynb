{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonewn/Wanted_AI_Onboarding/blob/main/Assignments/Wanted_Week3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugGR7pnI4WSe"
      },
      "source": [
        "# Week3_2 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- 한국어 코퍼스를 로드해 **WordPiece Tokenzier를 학습**시킬 수 있다.\n",
        "- 학습된 모델을 로드해 **encoding과 decoding을 수행**할 수 있다. \n",
        "\n",
        "\n",
        "\n",
        "### Reference\n",
        "- [BertWordPieceTokenizer 학습 소개 한국어 블로그](https://monologg.kr/2020/04/27/wordpiece-vocab/)\n",
        "- [huggingface python train tutorial](https://github.com/huggingface/tokenizers/blob/master/bindings/python/examples/train_bert_wordpiece.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T13:02:24.193088Z",
          "start_time": "2022-02-08T13:02:23.939474Z"
        },
        "id": "HlEy3xfY4WSh"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T12:20:56.576336Z",
          "start_time": "2022-02-08T12:20:56.574697Z"
        },
        "id": "cBrr7-gt4jnf"
      },
      "outputs": [],
      "source": [
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T13:03:10.552879Z",
          "start_time": "2022-02-08T13:03:09.944672Z"
        },
        "id": "6mC9lhsJ4WSh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tokenizers import BertWordPieceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T13:03:11.318888Z",
          "start_time": "2022-02-08T13:03:11.314522Z"
        },
        "id": "17g7UZ5g4WSi"
      },
      "outputs": [],
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T13:03:12.552228Z",
          "start_time": "2022-02-08T13:03:12.517904Z"
        },
        "id": "v3UlC7Jn4WSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead64f1a-e1a9-4853-f458-cef34193e784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoHa39WF5AFt"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHs8_LU04WSj"
      },
      "source": [
        "### 데이터 다운로드\n",
        "- 내 구글 드라이브에 데이터를 다운 받은 후 코랩에 드라이브를 마운트하면 데이터를 영구적으로 사용할 수 있다. \n",
        "- [데이터 다운로드 출처](https://ratsgo.github.io/embedding/downloaddata.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TWfB_xf5AFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16179c53-f0f8-443d-8898-0d2164b1fc3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPoV_wON5AF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfeb3411-ad36-4001-a98a-a18b2d81cfdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/원티드_AI온보딩\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/원티드_AI온보딩'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T13:05:10.693203Z",
          "start_time": "2022-02-08T13:05:05.809566Z"
        },
        "id": "4QPBJ6UZ4WSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5bb4c7-cc16-4b1f-e70c-f839a9917b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/u/0/uc?id=1kUecR7xO7bsHFmUI6AExtY5u2XXlObOG \n",
            "\n",
            "unzip:  cannot find or open processed.zip, processed.zip.zip or processed.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# 한국어 위키피디아 데이터 (토크나이즈되지 않은 텍스트) 로드\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/u/0/uc?id=1kUecR7xO7bsHFmUI6AExtY5u2XXlObOG\n",
        "!unzip processed.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip processed.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttFQr_yUP5l0",
        "outputId": "a1940be4-99e2-4a73-b263-fe3a6fbce893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  processed.zip\n",
            "   creating: processed/\n",
            "  inflating: processed/space-correct.model  \n",
            "  inflating: processed/processed_korquad.txt  \n",
            "  inflating: processed/processed_ratings_train.txt  \n",
            "  inflating: processed/processed_ratings_test.txt  \n",
            "  inflating: processed/processed_wiki_ko.txt  \n",
            "  inflating: processed/processed_ratings.txt  \n",
            "  inflating: processed/corrected_ratings_corpus.txt  \n",
            "  inflating: processed/soyword.model  \n",
            "  inflating: processed/processed_review_movieid.txt  \n",
            "  inflating: processed/corrected_ratings_train.txt  \n",
            "  inflating: processed/corrected_ratings_test.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKjNsKAk5AF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980057fe-4a44-4091-cc5b-389d78b38fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My current directory : /content/drive/MyDrive/원티드_AI온보딩\n"
          ]
        }
      ],
      "source": [
        "_CUR_DIR = os.path.abspath(os.curdir)\n",
        "print(f\"My current directory : {_CUR_DIR}\")\n",
        "_DATA_DIR = os.path.join(_CUR_DIR, \"processed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIO4LFu67z72"
      },
      "source": [
        "### 한국어 위키피디아 코퍼스로 WordPiece tokenizer 학습\n",
        "- 한국어 위키 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(_DATA_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjTfMOL_Q2t2",
        "outputId": "86426dee-2ce5-4bb2-99c3-f05531dd85f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/원티드_AI온보딩/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T13:07:46.216505Z",
          "start_time": "2022-02-08T13:07:41.735392Z"
        },
        "id": "xkjqztIA4WSl"
      },
      "outputs": [],
      "source": [
        "# processed_wiki_ko.txt 파일 불러오기\n",
        "\n",
        "docs = pd.read_table(os.path.join(_DATA_DIR,'processed_wiki_ko.txt'),header=None,sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T13:07:55.901375Z",
          "start_time": "2022-02-08T13:07:55.898177Z"
        },
        "id": "WAKB6bbt4WSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491f8e41-bf92-4561-cfb0-0ce3b959f1da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# wiki documents: 311,237\n"
          ]
        }
      ],
      "source": [
        "print(f\"# wiki documents: {len(docs):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T15:04:42.728698Z",
          "start_time": "2022-02-08T15:04:42.725712Z"
        },
        "id": "rsSDiCKC7z73"
      },
      "outputs": [],
      "source": [
        "# Word Piece Tokenizer 인스턴스 생성\n",
        "tokenizer = BertWordPieceTokenizer(\n",
        "    clean_text=True,\n",
        "    handle_chinese_chars=True,\n",
        "    strip_accents=False, # 악센트가 있는 character의 악센트를 제거하려면? (ex. é → e)\n",
        "    lowercase=False, # 한국어는 대소문자가 없는데 소문자 변환이 필요한지?\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T15:07:44.027617Z",
          "start_time": "2022-02-08T15:06:26.871651Z"
        },
        "id": "d2XCyb-R7z73"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "# files: 'processed_wiki_ko.txt'\n",
        "# vocab_size: 30,000\n",
        "# min_frequency: 2\n",
        "# special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "# limit_alphabet: 1,000\n",
        "# wordpieces_prefix: '##'\n",
        "\n",
        "tokenizer.train(\n",
        "    files = os.path.join(_DATA_DIR,'processed_wiki_ko.txt'),\n",
        "    vocab_size = 30000,\n",
        "    min_frequency = 2,\n",
        "    show_progress = True,\n",
        "    special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n",
        "    limit_alphabet = 1000,\n",
        "    wordpieces_prefix = '##',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T15:09:05.258756Z",
          "start_time": "2022-02-08T15:09:05.245393Z"
        },
        "id": "XP_TSZ4W7z74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffbcf6d-f615-4211-a2e0-9c244cb1b78b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./wordpiece-vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "tokenizer.save_model(\".\", \"wordpiece\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C44J9vSg7z74"
      },
      "source": [
        "### Encoding\n",
        "- 저장된 토크나이즈 파일을 로드해 `BertWordPieceTokenizer` 인스턴스를 생성하고 다음을 수행하자. \n",
        "    - 사전(vocab)의 단어 개수를 출력\n",
        "    - 문장을 토크나이징한 후 토큰 id와 토큰 string을 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipYjhaM05AGH"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertWordPieceTokenizer(\n",
        "    vocab = './wordpiece-vocab.txt',\n",
        "    lowercase = False,\n",
        "    strip_accents = False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5MsfhF_5AGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2a3e15-cd2f-4d8c-c72f-ddec613333ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# 사전 단어 개수 출력\n",
        "tokenizer.get_vocab_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp9kVECa5AGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cac55be-8586-4c1d-b8aa-f0a8c9d738bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 7864, 20862, 16, 509, 3371, 5566, 2778, 5757, 16, 3]\n",
            "['[CLS]', '안녕', '##하세요', '.', '버', '##트를', '사용한', '모델', '##입니다', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "text = \"안녕하세요. 버트를 사용한 모델입니다.\"\n",
        "\n",
        "# 토크나이즈한 후 토큰의 id를 출력하라 \n",
        "encoding = tokenizer.encode(text)\n",
        "token_ids = encoding.ids\n",
        "print(token_ids)\n",
        "\n",
        "# 토크나이즈한 후 각 토큰(string)을 출력하라.\n",
        "tokens = encoding.tokens\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-08T15:12:06.621489Z",
          "start_time": "2022-02-08T15:12:06.618447Z"
        },
        "id": "mzrnMuSr7z74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80bf3040-68b3-4761-a715-0d7b956392b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '킹', '##받', '##네', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# 신조어를 토크나이징할 수 있는지 테스트해보자.\n",
        "text = \"킹받네\"\n",
        "tokens = tokenizer.encode(text).tokens\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewQ4JTbR5AGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b85961-d5f2-46ae-cbdb-48b5432892d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 1, 3]\n",
            "['[CLS]', '[UNK]', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# 사전에 없는 단어는 어떻게 토크나이즈 되는가?\n",
        "text = \"뷁\"\n",
        "encoding = tokenizer.encode(text)\n",
        "unknown_token_ids = encoding.ids # 토큰 id\n",
        "unknown_tokens = encoding.tokens # 토큰\n",
        "print(unknown_token_ids)\n",
        "print(unknown_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgO1JJyM5AGN"
      },
      "source": [
        "### Decoding\n",
        "- 토큰 id를 원래 문장으로 디코딩하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew4gUQ-F5AGN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec4b7e87-79fe-4b9d-cc0c-2996da00bfe4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'안녕하세요. 버트를 사용한 모델입니다.'"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# 원래 문장: \"안녕하세요. 버트를 사용한 모델입니다.\"\n",
        "tokenizer.decode(token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_5JG3PP5AGP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "28819650-3b20-40ce-cbbc-97c2d8906cdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# 사전에 없는 단어는 어떻게 디코딩되는가?\n",
        "encoding = tokenizer.encode('뷁')\n",
        "unknown_token_ids = encoding.ids\n",
        "tokenizer.decode(unknown_token_ids)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Wanted_Week3_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}